%% -*- coding:utf-8 -*-
\subsection{Random Variable. Distribution Functions}

\begin{definition}[Random Variable]
\label{def:random_variable}
If $\Omega$ is an event space (see definition \autoref{def:events_set}), then the mapping $X: \Omega \to \mathbb{R}$ is called a random variable.
\end{definition}

It is worth noting that if a random variable is denoted with a capital letter $X$, then a specific realization is denoted with a lowercase letter $x$, i.e., if $\omega \in \Omega$, then $x = X(\omega)$. In particular, for discrete random variables, each realization $x = X(\omega)$ can be associated with some probability $P\left(x\right) = P\left(\omega\right)$. Otherwise, distribution functions are used.

\begin{definition}[Distribution Function of a Random Variable]
The distribution function $F_X$ of a random variable $X$ is a function $F_X : \mathbb{R} \to [0,1]$, which is given by the formula
\[
F_X \left(x\right) = P\left(X \le x\right),
\]
i.e., the distribution function at argument $x$ is equal to the probability of those events $\omega \in \Omega$ for which $X(\omega) \le x$.
\end{definition}

\begin{definition}[Density of Distribution of a Random Variable]
In the case of continuous random variables, it makes sense to speak of the density of distribution $f_X\left(x\right)$, which is defined by the following expression
\[
f_X\left(x\right) = 
\frac{d F_X\left(x\right)}{d x}
\]
\end{definition}

\begin{definition}[Expectation of a Random Variable]
For a discrete random variable, i.e., if the set of elementary events is countable, the expectation $E\left(X\right)$ of a random variable $X$ is defined by the following relation
\[
E\left(X\right) = \sum_\omega p_\omega \cdot X(\omega) = 
\sum_x p_x \cdot x,
\]
where the summation is over all possible elementary outcomes $\omega$, $x = X(\omega)$, $p_\omega = p_{X(\omega)} = p_x$. For continuous random variables, this relation transforms into
\[
E\left(X\right) = \int_{-\infty}^\infty x \cdot f_X\left(x\right) dx.
\]
\end{definition}

TBD